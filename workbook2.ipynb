{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workbook 2: Pandas and SQL\n",
    "\n",
    "All resources, unless otherwise specified, are created by Nikhil Chinchalkar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've already seen some of the stuff we can do with Pandas, and we're going to expand on that with some more advanced filtering and general data cleaning skills. We'll also learn the basics of SQL (which is another language), and compare using SQL and Pandas to perform basic filtering tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A: Filtering In Pandas Vs. SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw earlier that we can do some basic filtering based on columns using some basic Pandas functions. We can also do the same stuff using SQL (and in my opinion, it's much easier). Let's start by importing `duckdb`, which is a library that allows us to run SQL (which is a different language) commands in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import duckdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above gave you an error, try commenting out the line below and re-running it once the stuff below has finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting duckdb\n",
      "  Downloading duckdb-1.4.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (14 kB)\n",
      "Downloading duckdb-1.4.1-cp313-cp313-macosx_11_0_arm64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: duckdb\n",
      "Successfully installed duckdb-1.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install duckdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by importing data from [Netflix TV Shows and Movies](https://www.kaggle.com/datasets/victorsoeiro/netflix-tv-shows-and-movies?select=titles.csv), which is available on Kaggle. This dataset shows information for all shows and movies that were available to Netflix users in July 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = pd.read_csv('titles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, let's just do some random filtering and grouping to show the difference between Pandas and SQL. Let's say we only wanted to look at TV Shows with more than 1 season and only cared about the columns `id` and `title`. We can use the `type` variable to do so, and the filter down the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id                         title\n",
      "5   ts22164  Monty Python's Flying Circus\n",
      "35  ts20681                      Seinfeld\n",
      "44  ts22082                  Knight Rider\n",
      "45  ts21715              Thomas & Friends\n",
      "46  ts20678             Saved by the Bell\n"
     ]
    }
   ],
   "source": [
    "#pandas first:\n",
    "filtered_titles_PD = titles[(titles['type'] == 'SHOW') & (titles['seasons'] > 1)][['id','title']]\n",
    "\n",
    "print(filtered_titles_PD.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That above Pandas syntax is a little weird and unintuitive. It doesn't exactly fly off the tongue either. Let's see the same exact task in SQL. First, I'll explain what the SQL syntax looks like. Most commands will start with a `SELECT` function, which just tells Python to take some columns `FROM` a dataframe, which is our next function. THen, there's a bunch of syntax that can follow, I'm using a `WHERE` call to specify that I want to take data *where* a condition is satisfied. That condition? where `type = 'SHOW' AND seasons > 1`. Note that the surrounding structure is important - you need the initial duckdb.sql and the triple quotes and the `df()` following to convert the task back into a dataframe.\n",
    "\n",
    "Note that we tend to capitalize functions in SQL and leave other stuff lowercase - there's no difference in not doing that, it just makes it a bit easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                         title\n",
      "0  ts22164  Monty Python's Flying Circus\n",
      "1  ts20681                      Seinfeld\n",
      "2  ts22082                  Knight Rider\n",
      "3  ts21715              Thomas & Friends\n",
      "4  ts20678             Saved by the Bell\n"
     ]
    }
   ],
   "source": [
    "#SQL next:\n",
    "filtered_titles_SQL = duckdb.sql(\"\"\"SELECT id, title FROM titles\n",
    "                                 WHERE type = 'SHOW' AND seasons > 1\"\"\").df()\n",
    "\n",
    "print(filtered_titles_SQL.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the above tasks accomplished the same thing - but one is significantly easier than the other (SQL). I'm going to continue to use SQL for most of my data cleaning tasks, including grouping, which is next:\n",
    "\n",
    "Grouping is kind of self explanatory - you take an item in a column and put all the rows that match it together. Let's say we wanted to group by `SHOW`s and `MOVIE`s to see how many of each our original dataset has:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    type  Count  AverageScore\n",
      "0  MOVIE   3744      6.246748\n",
      "1   SHOW   2106      6.977927\n"
     ]
    }
   ],
   "source": [
    "titles_count = duckdb.sql(\"\"\"SELECT type, COUNT() AS Count, AVG(imdb_score) AS AverageScore \n",
    "                          FROM titles\n",
    "                          GROUP BY type\"\"\").df()\n",
    "\n",
    "print(titles_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though the result is pretty simple, there's a lot going on in the above call. First, we're selecting certain columns that we want to print out, including ones that we're creating based on other column data (count and average). The `AS` keyword is basically us renaming the column to something easier to interpret - you can remove the AS command to see how our output changes. Then, we specify that we want the data to be from our `titles` dataframe, and group by the `type`.\n",
    "\n",
    "Take a second to really understand what's going on in the above call - a lot of this stuff are things that we need to do for every dataset when doing exploratory data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's now your turn: try and do the following from the `credits` csv that you downloaded from Kaggle. Completing this step will involve some stuff from prior notebooks too.\n",
    "\n",
    "1. Read in the CSV, saving it in a variable titled `credits`\n",
    "2. Using SQL do the following (from the `credits` dataframe):\n",
    "   1. Group by each `person_id` (since some actors might have the same name)\n",
    "   2. Count the number of roles that each actor `person_id` is attributed to (similar to what we did above), renaming the column to `CountRoles`\n",
    "   3. Use the [ORDER BY](https://www.w3schools.com/sql/sql_orderby.asp) command to sort the `CountRoles` in descending order\n",
    "   4. Make sure to select the `name` and `CountRoles` columns only (you should use `FIRST(name)` in your select instead of just `name`, since there's more than one name that we're grouping by) \n",
    "   5. Save this dataframe to a variable titled `topActors`\n",
    "3. Using Pandas, print the first 5 rows of `topActors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  name  CountRoles\n",
      "0  Kareena Kapoor Khan          25\n",
      "1          Boman Irani          25\n",
      "2       Shah Rukh Khan          23\n",
      "3     Takahiro Sakurai          21\n",
      "4     Amitabh Bachchan          20\n"
     ]
    }
   ],
   "source": [
    "#A1 your code here\n",
    "#part 1 is already done for you\n",
    "credits = pd.read_csv('credits.csv')\n",
    "topActors = duckdb.sql(\"\"\"SELECT name, \n",
    "                          Count(person_id) AS CountRoles FROM credits\n",
    "                           GROUP BY person_id, name\n",
    "                          ORDER BY CountRoles DESC\n",
    "                          \"\"\").df()\n",
    "print (topActors.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected Output:\n",
    "```\n",
    "         first(\"name\")  CountRoles\n",
    "0  Kareena Kapoor Khan          25\n",
    "1          Boman Irani          25\n",
    "2       Shah Rukh Khan          23\n",
    "3     Takahiro Sakurai          21\n",
    "4         Paresh Rawal          20\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above section details pretty much all of the basic SQL commands, there's obviously more, but for our sake, that's a pretty solid foundation. There's one more important SQL command, though, that we need to address. Before we do that, we'll talk about NANs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B: Dealing With NANs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NANs, or 'Not a Number' is a type of value in Python that exists when we have a 'blank' in a dataset. Essentially, we see an NaN in a dataset when there is no number to fill in that value. We can see an NaN in practice by looking at the bottom of the `credits` dataframe, in the `character` column. Here, the character that Julian Gaviria plays is unknown/null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>character</th>\n",
       "      <th>role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77796</th>\n",
       "      <td>736339</td>\n",
       "      <td>tm1059008</td>\n",
       "      <td>Adelaida Buscato</td>\n",
       "      <td>María Paz</td>\n",
       "      <td>ACTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77797</th>\n",
       "      <td>399499</td>\n",
       "      <td>tm1059008</td>\n",
       "      <td>Luz Stella Luengas</td>\n",
       "      <td>Karen Bayona</td>\n",
       "      <td>ACTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77798</th>\n",
       "      <td>373198</td>\n",
       "      <td>tm1059008</td>\n",
       "      <td>Inés Prieto</td>\n",
       "      <td>Fanny</td>\n",
       "      <td>ACTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77799</th>\n",
       "      <td>378132</td>\n",
       "      <td>tm1059008</td>\n",
       "      <td>Isabel Gaona</td>\n",
       "      <td>Cacica</td>\n",
       "      <td>ACTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77800</th>\n",
       "      <td>1950416</td>\n",
       "      <td>tm1059008</td>\n",
       "      <td>Julian Gaviria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DIRECTOR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       person_id         id                name     character      role\n",
       "77796     736339  tm1059008    Adelaida Buscato     María Paz     ACTOR\n",
       "77797     399499  tm1059008  Luz Stella Luengas  Karen Bayona     ACTOR\n",
       "77798     373198  tm1059008         Inés Prieto         Fanny     ACTOR\n",
       "77799     378132  tm1059008        Isabel Gaona        Cacica     ACTOR\n",
       "77800    1950416  tm1059008      Julian Gaviria           NaN  DIRECTOR"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credits.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaNs can be a problem for certain applications and calculations. You can't take the mean of a column with NaNs in it, and graphing NaNs can look a bit weird. \n",
    "\n",
    "Dealing with NaNs is a large part of the data cleaning process, and is something that depends on your application. Sometimes you might want to filter out the NaNs in one column, and leave in NaNs in another, and sometimes you might want to replace NaNs with actual values like 0s. For now, I'll just show you how to remove all NaNs in all columns, which is useful for regression applications, since most models require no NaNs as inputs.\n",
    "\n",
    "To do so, we just use Pandas and a simple command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>character</th>\n",
       "      <th>role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77795</th>\n",
       "      <td>368473</td>\n",
       "      <td>tm1059008</td>\n",
       "      <td>Aída Morales</td>\n",
       "      <td>Maritza</td>\n",
       "      <td>ACTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77796</th>\n",
       "      <td>736339</td>\n",
       "      <td>tm1059008</td>\n",
       "      <td>Adelaida Buscato</td>\n",
       "      <td>María Paz</td>\n",
       "      <td>ACTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77797</th>\n",
       "      <td>399499</td>\n",
       "      <td>tm1059008</td>\n",
       "      <td>Luz Stella Luengas</td>\n",
       "      <td>Karen Bayona</td>\n",
       "      <td>ACTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77798</th>\n",
       "      <td>373198</td>\n",
       "      <td>tm1059008</td>\n",
       "      <td>Inés Prieto</td>\n",
       "      <td>Fanny</td>\n",
       "      <td>ACTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77799</th>\n",
       "      <td>378132</td>\n",
       "      <td>tm1059008</td>\n",
       "      <td>Isabel Gaona</td>\n",
       "      <td>Cacica</td>\n",
       "      <td>ACTOR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       person_id         id                name     character   role\n",
       "77795     368473  tm1059008        Aída Morales       Maritza  ACTOR\n",
       "77796     736339  tm1059008    Adelaida Buscato     María Paz  ACTOR\n",
       "77797     399499  tm1059008  Luz Stella Luengas  Karen Bayona  ACTOR\n",
       "77798     373198  tm1059008         Inés Prieto         Fanny  ACTOR\n",
       "77799     378132  tm1059008        Isabel Gaona        Cacica  ACTOR"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credits_cleaned = credits.dropna()\n",
    "credits_cleaned.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that there's no longer that NaN at the bottom of the list. Note that removing certain rows can cause the row indices to get messed up - there's no longer going to be rows at certain indices. To fix that and ensure our rows are continuous, we can just call `reset_index`, setting `drop=True` to make sure we don't add another column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>character</th>\n",
       "      <th>role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68024</th>\n",
       "      <td>368473</td>\n",
       "      <td>tm1059008</td>\n",
       "      <td>Aída Morales</td>\n",
       "      <td>Maritza</td>\n",
       "      <td>ACTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68025</th>\n",
       "      <td>736339</td>\n",
       "      <td>tm1059008</td>\n",
       "      <td>Adelaida Buscato</td>\n",
       "      <td>María Paz</td>\n",
       "      <td>ACTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68026</th>\n",
       "      <td>399499</td>\n",
       "      <td>tm1059008</td>\n",
       "      <td>Luz Stella Luengas</td>\n",
       "      <td>Karen Bayona</td>\n",
       "      <td>ACTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68027</th>\n",
       "      <td>373198</td>\n",
       "      <td>tm1059008</td>\n",
       "      <td>Inés Prieto</td>\n",
       "      <td>Fanny</td>\n",
       "      <td>ACTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68028</th>\n",
       "      <td>378132</td>\n",
       "      <td>tm1059008</td>\n",
       "      <td>Isabel Gaona</td>\n",
       "      <td>Cacica</td>\n",
       "      <td>ACTOR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       person_id         id                name     character   role\n",
       "68024     368473  tm1059008        Aída Morales       Maritza  ACTOR\n",
       "68025     736339  tm1059008    Adelaida Buscato     María Paz  ACTOR\n",
       "68026     399499  tm1059008  Luz Stella Luengas  Karen Bayona  ACTOR\n",
       "68027     373198  tm1059008         Inés Prieto         Fanny  ACTOR\n",
       "68028     378132  tm1059008        Isabel Gaona        Cacica  ACTOR"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credits_cleaned = credits_cleaned.reset_index(drop=True)\n",
    "credits_cleaned.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that our row indices have reset, and while it's a bit difficult to show that they're continuous, just trust me that they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C: Left Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last SQL command we'll learn is arguably the most important one. It deals with when we want to merge two datasets together (horizontally). You might have noticed that we have two separate but similar datasets, that can be merged *on* the `id` column. That is, each actor role corresponds to a movie `id`, since each actor plays a role *in* a movie. So, we can merge the two datasets `credits` and `titles`. \n",
    "\n",
    "There's a bunch of ways to do that, but the easiest is to perform a left join, which means we have two datasets and a column to combine on (the column shares the same data). Then, for each column value (row) in the right dataset, we join that row in every instance of the value in the left dataset. It's easier to see what I mean in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a way of doing this using Pandas, but like we saw above, that method is a bit unintuitive, so I'll use SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>name</th>\n",
       "      <th>character</th>\n",
       "      <th>title</th>\n",
       "      <th>imdb_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tm84618</td>\n",
       "      <td>Robert De Niro</td>\n",
       "      <td>Travis Bickle</td>\n",
       "      <td>Taxi Driver</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tm84618</td>\n",
       "      <td>Jodie Foster</td>\n",
       "      <td>Iris Steensma</td>\n",
       "      <td>Taxi Driver</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tm84618</td>\n",
       "      <td>Albert Brooks</td>\n",
       "      <td>Tom</td>\n",
       "      <td>Taxi Driver</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tm84618</td>\n",
       "      <td>Harvey Keitel</td>\n",
       "      <td>Matthew 'Sport' Higgins</td>\n",
       "      <td>Taxi Driver</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tm84618</td>\n",
       "      <td>Cybill Shepherd</td>\n",
       "      <td>Betsy</td>\n",
       "      <td>Taxi Driver</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movie_id             name                character        title  imdb_score\n",
       "0  tm84618   Robert De Niro            Travis Bickle  Taxi Driver         8.2\n",
       "1  tm84618     Jodie Foster            Iris Steensma  Taxi Driver         8.2\n",
       "2  tm84618    Albert Brooks                      Tom  Taxi Driver         8.2\n",
       "3  tm84618    Harvey Keitel  Matthew 'Sport' Higgins  Taxi Driver         8.2\n",
       "4  tm84618  Cybill Shepherd                    Betsy  Taxi Driver         8.2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dataset = duckdb.sql(\"\"\"SELECT credits.id AS movie_id, credits.name, credits.character, titles.title ,titles.imdb_score \n",
    "                            FROM credits\n",
    "                            LEFT JOIN titles ON credits.id = titles.id\"\"\").df()\n",
    "\n",
    "merged_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above cell, there's a lot going on. First, we're using some new notation to help Python identify which columns we actually want to take and which dataframes they actually come from. Then, we see some familiar syntax in our `FROM` statement, before we're met with another new function in `LEFT JOIN`. Here, we're just saying that we want to left join starting from `credits` (the first dataframe is the left one) `ON` the common column which corresponds to `id` in `credits` and also just happens to be `id` in `titles`. Note that they don't need to be the same name, it just so happens to be like that in this case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our output here is as expected: we see that each of the rows in the right dataframe (a movie) is being matched to a corresponding row in the left dataframe (actors). That is, each actor role is being matched with the movie that the role comes from. Since there are multiple roles in each movie, it makes sense that we see Taxi Driver a bunch of times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this might seem a bit complicated right now, it should become second nature with some practice. Also note that there are a ton of other merging methods (right joins, inner joins, full joins, etc.) but most of the time in the data science world, you'll rarely see these other types of joins. Besides, with some manipulation you could get the equivalent of a right join with a left join, and vice versa. Essentially, yeah there's a bunch of joins, but they all can reach the same goal, which is just to have one merged dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just went over a lot of stuff, but that's pretty much all the SQL commands that I've had to use in my own data science journey, with some minor tweaks to syntax here and there. It's now time to do your own practice:\n",
    "\n",
    "In the following code block, do the following:\n",
    "\n",
    "1. Make a new dataframe, called `directors`, from the `credits` dataframe, only looking at directors (look at the `role` column)\n",
    "2. Perform a left join on the directors dataframe (using `titles`) to match up each director to the film they directed (this should look similar to the above)\n",
    "3. Use the GROUP BY attribute to group by each director's `name`\n",
    "4. Use the COUNT() function to list the number of movies each director directed (rename this to `count`)\n",
    "5. Use the AVG() function to find the average `imdb_score` of each of the movies (rename this to `score`)\n",
    "6. Make a new dataframe from `directors` titled `top_directors` where you filter the `directors` who directed at least 5 movies\n",
    "7. Sort `top_directors` by `imdb_score`, in descending order\n",
    "8. Print the first 5 rows of `top_directors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>count</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Martin Scorsese</td>\n",
       "      <td>6</td>\n",
       "      <td>8.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mani Ratnam</td>\n",
       "      <td>6</td>\n",
       "      <td>7.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Song Hyun-wook</td>\n",
       "      <td>6</td>\n",
       "      <td>7.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anurag Kashyap</td>\n",
       "      <td>8</td>\n",
       "      <td>7.271429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shannon Hartman</td>\n",
       "      <td>7</td>\n",
       "      <td>7.257143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  count     score\n",
       "0  Martin Scorsese      6  8.160000\n",
       "1      Mani Ratnam      6  7.733333\n",
       "2   Song Hyun-wook      6  7.375000\n",
       "3   Anurag Kashyap      8  7.271429\n",
       "4  Shannon Hartman      7  7.257143"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#C1 your code here\n",
    "directors = duckdb.sql(\"\"\"  \n",
    "                        SELECT credits.name, COUNT(*) AS count, AVG(titles.imdb_score) as score \n",
    "                        FROM credits \n",
    "                        LEFT JOIN titles ON credits.id = titles.id\n",
    "                        WHERE credits.role = 'DIRECTOR'\n",
    "                        GROUP BY credits.name\n",
    "                       \"\"\").df()\n",
    "\n",
    "top_directors = duckdb.sql(\"\"\" SELECT * FROM directors \n",
    "                           WHERE count >5\n",
    "                           ORDER BY score DESC\"\"\").df()\n",
    "\n",
    "top_directors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected Output:\n",
    "\n",
    "```\n",
    "              name  count     score\n",
    "0  Martin Scorsese      6  8.160000\n",
    "1      Mani Ratnam      6  7.733333\n",
    "2   Song Hyun-wook      6  7.375000\n",
    "3   Anurag Kashyap      8  7.271429\n",
    "4  Shannon Hartman      7  7.257143\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This last assignment is pretty difficult and requires a solid foundation in SQL. If you completed it, you should feel confident about your ability to solve future problems you encounter in SQL. If you completed it and still want a challenge, try to do it in a single SQL statement (hint: you should look into the [HAVING](https://www.w3schools.com/sql/sql_having.asp) function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try and make a estimation for a frequency distribution of scores across our `titles` dataset. To do this, we'll need to do the following:\n",
    "\n",
    "1. Select the `CEIL()` of the `imdb_score`s from the `titles` dataframe (rename this to `score`)\n",
    "2. Select the `COUNT()` of the number of movies that fall under each score (rename this to `freq`)\n",
    "3. `GROUP BY` each score\n",
    "4. Sort the dataframe in descending order by the `score` attribute\n",
    "5. Remove NaNs in the score column using the `dropna()` function (using Pandas)\n",
    "6. Display the full dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C2 your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected Output:\n",
    "\n",
    "```\n",
    "   score  freq\n",
    "0   10.0    11\n",
    "1    9.0   390\n",
    "2    8.0  1490\n",
    "3    7.0  1835\n",
    "4    6.0  1094\n",
    "5    5.0   376\n",
    "6    4.0   125\n",
    "7    3.0    39\n",
    "8    2.0     8\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the next lesson, you'll easily be able to plot this data in a nice histogram plot."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datajournal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
